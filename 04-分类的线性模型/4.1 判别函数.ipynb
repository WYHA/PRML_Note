{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 前言\n",
    "---\n",
    "\n",
    "- **决策边界（decision boundary）或者决策面（decision surface）**\n",
    "\n",
    "    输入空间被划分为不同的决策区域。被划分的边界被叫做决策边界或者决策面。\n",
    "- **分类线性模型**\n",
    "\n",
    "    分类线性模型是指输入向量是$x$的线性函数。\n",
    "- **线性可分（linearly separable）**\n",
    "\n",
    "    定义为D维输⼊空间中的(D-1)维超平⾯【例如在二维平面上，决策边界是一维的一根线。】。如果数据集可以被线性决策⾯精确地分类，那么我们  说这个数据集是线性可分的。\n",
    "- **“1-of-K”编码规则**\n",
    "\n",
    "    对多分类的问题，类别有K类，那么类别向量$t$的长度就为K，其中，该类别如果为$C_j$，那么该类别向量的第$j$个向量为1，其余均为0。例如，如果我们有5个类别，那么来⾃第2个类别的模式给出的⽬标向量为：\n",
    "\n",
    "$$\n",
    "t=(0,1,0,0,0)^T\n",
    "$$\n",
    "\n",
    "- **从线性回归到线性分类。**\n",
    "\n",
    "    在回归模型中，最简单的模型的形式就是y(x)=(w^Tx+w_0)，然而在分类问题中。我们想预测的是离散的类别标签。所以做以下推广\n",
    "\n",
    "$$\n",
    "y(x)=f(w^Tx+w_0) \\tag{4.3}\n",
    "$$\n",
    "\n",
    "    在机器学习的⽂献中，$f(\\cdot)$被称为激活函数（activation function），⽽它的反函数在统计学的⽂献中被称为链接函数（link function）\n",
    "\n",
    "- **判别函数**\n",
    "\n",
    "    判别函数是⼀个以向量x为输⼊，把它分配到K个类别中的某⼀个类别（记作Ck）的函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.1.1 二分类\n",
    "---\n",
    "\n",
    "线性判别函数最简单的形式是输入向量的线性函数。\n",
    "\n",
    "$$\n",
    "y(x)=w^Tx+w_0 \\tag{4.4}\n",
    "$$\n",
    "\n",
    "其中$w$被称为权向量（weight vector），$w_0$被称为偏置（bias）。注意不要把这⾥的偏置与统计学中的偏置弄混淆。\n",
    "\n",
    "- 权向量$w$确定了决策面的方向\n",
    "\n",
    "    对一个输入向量$x$，如果有$y(x)\\geqslant 0$那么它被分到$C_1$类中， 否则分到$C_2$类中，对在决策面上的两个点$x_A$和$x_B$，我们有$y(x_A)=y(x_B)=0$，那么可以有$w^T(x_A-x_B)=0$，权向量$w$与决策面正交，所以权向量$w$确定了决策面的方向。\n",
    "\n",
    "\n",
    "![](https://gitee.com/data2world/OpimizationPhoto/raw/master/%E7%AC%AC4%E7%AB%A0/4.1.png)\n",
    "\n",
    "\n",
    "为了记号简介，做以下变换:$x_0=1$，那么$\\tilde{w}=(w_0,w)$以及$\\tilde{x}=(x_0,x)$,从而：\n",
    "$$\n",
    "y(x)=\\tilde{w}^T\\tilde{x} \\tag{4.8}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.1.2 多分类\n",
    "---\n",
    "如下图所示，无论是（one-versus-the-rest）分类器还是(one-versus-one）分类器。都会造成输⼊空间中的⽆法分类的区域。\n",
    "![](https://gitee.com/data2world/OpimizationPhoto/raw/master/%E7%AC%AC4%E7%AB%A0/4.2.png)\n",
    "\n",
    "所以我们引入K类判别函数,这是由K个线性函数组成的，形式如下\n",
    "$$\n",
    "y_k(x)=w^T_Kx+w_{k0} \\tag{4.9}\n",
    "$$\n",
    "\n",
    "\n",
    "接下来，确定决策面。对于点$x$，如果对于所有的$j\\neq k$都有$y_k(x)>y_j(x)$，就把他分到$C_k$类。于是，我们就得到了决策面为$y_k(x)=y_j(x)$。\n",
    "$$\n",
    "(w_k-w_j)^Tx+(w_{k0}-w_{j0})=0 \\tag{4.10}\n",
    "$$\n",
    "\n",
    "这样的决策区域是单"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 用于分类的最小平方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.1.4 Fisher线性判别函数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.1.5 与最小平方的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.1.6 用于多分类的Fisher判别函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.1.7 感知器算法（Perceptrons）\n",
    "---\n",
    "\n",
    "Rosenblatt在1962年提出的感知器算法。我们先看下面比较形象的图片\n",
    "![](https://gitee.com/data2world/PRML/raw/master/CH04/ganzhiqi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "现在我们有一堆数据，即上面的圈圈和叉叉。现在我们的任务是找到一个**函数**将这一堆数据分成两类（也就是圈圈一堆、叉叉一堆）。这个函数我们可以用类似直线的方程$w \\cdot x+b$表示。接着我们把它变得更加的向量化一点：\n",
    "$$\n",
    "y(x) = f(\\vec{w}^T\\phi(\\vec{x})) \\tag {4.52}\n",
    "$$\n",
    "\n",
    "其中非线性激活函数$f(\\cdot)$是一个阶梯函数，形式为\n",
    "$$\n",
    "f(a) = \\begin{cases} +1, & a \\geq 0 \\\\\\\\  -1, & a<0\\end{cases} \\tag {4.53}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 感知器的误差函数 \n",
    "在感知器中，**如果我们将错误的分类数作为误差函数，那么这样的函数必然是分段函数，不是参数$w$和$b$的可导函数。那么我们就很难优化参数**。这里我们考虑另外的误差函数，即感知器准则（perceptron criterion）。\n",
    "\n",
    "- 现在我们有$C_1$类和$C_2$类。我们的目的是找到**权向量$w$**使得$w^T\\phi(x_n)>0$都属于$C_1$。而$w^T\\phi(x_n)<0$都属于$C_2$。\n",
    "- 然后激活函数$\\in \\{-1,1\\}$。那么我们的目标就变成了$w^T\\phi(x_n)t_n>0$。如果误分类了，那么前面的式子就为负数。\n",
    "- 根据上面的推导，我们知道了需要最小化$-w^T\\phi(x_n)t_n$。感知器准则如下\n",
    "\n",
    "$$\n",
    "E_P(\\vec{w})=-\\sum_{n\\in \\cal{M}}w^T\\phi_nt_n \\tag{4.54}\n",
    "$$\n",
    "\n",
    "其中$\\phi_n=\\phi(x_n)$，另外$\\cal{M}$表示所有误分类的集合。我们对误差函数使用**随机梯度下降算法**。这样，权向量$w$的变化为\n",
    "\n",
    "$$\n",
    "\\vec{w}^{\\tau+1} = \\vec{w}^{\\tau}-\\eta\\nabla E_P(\\vec{w})=\\vec{w}^{\\tau}+\\eta\\phi_nt_n \\tag{4.55}\n",
    "$$\n",
    "\n",
    "- $\\eta$是学习率。\n",
    "- $\\tau$是一个整数，是算法运行次数的索引\n",
    "\n",
    "感知器的算法可以简单的如下表示\n",
    "![](https://gitee.com/data2world/PRML/raw/master/CH04/4.7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "如上图所示。给出了⼆维特征空间($\\phi_1,\\phi_2$)中的来⾃两个类别的数据点（红⾊和蓝⾊）。左上图给出了初始参数向量$\\vec{w}$，表⽰为⿊⾊箭头，以及对应的决策边界（⿊⾊直线），其中箭头指向被分类为红⾊类别的决策区域。**⽤绿⾊圆圈标出的数据点被误分类**，因此它的特征向量被加到当前的权向量中，给出了新的决策边界，如右上图所⽰。左下图给出了下⼀个误分类的点，⽤绿⾊圆圈标出，它的特征向量再次被加到权向量上，给出了右下图的决策边界。这个边界中所有的数据点都被正确分类。\n",
    "\n",
    "如果我们考虑感知器学习算法中⼀次权值更新的效果，我们可以看到，⼀个误分类模式对于误差函数的贡献会逐渐减⼩。【这里我么让学习率为1】\n",
    "\n",
    "$$\n",
    "-w^{(\\tau+1)T}\\phi_nt_n=-w^{(\\tau)T}\\phi_nt_n-(\\phi_nt_n)^Tphi_nt_n < -w^{(\\tau)T}\\phi_nt_n \\tag{4.56}\n",
    "$$\n",
    "\n",
    "\n",
    "### 感知器总结\n",
    "\n",
    "- 权向量的改变会使得某些之前正确分类的样本变为误分类。因此感知器学习规则并不保证在每个阶段都会减⼩整体的误差函数。\n",
    "- 对于线性不可分的数据集，感知器算法永远不会收敛。\n",
    "- 感知器算法⽆法提供概率形式的输出，也⽆法直接推⼴到K > 2个类别的情形。然⽽，最重要的局限性是它基于固定基函数的线性组合。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Refrence\n",
    "【1】[https://www.pearsonhighered.com/assets/samplechapter/0/1/3/1/0131471392.pdf](https://www.pearsonhighered.com/assets/samplechapter/0/1/3/1/0131471392.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "880px",
    "left": "0px",
    "right": "1708px",
    "top": "107px",
    "width": "244px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
