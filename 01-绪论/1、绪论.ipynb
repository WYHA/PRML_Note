{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">PRML的第一章的绪论部分主要讲了一些机器学习的基本概念。如：训练集、测试集、泛化、有监督学习、无监督学习、特征抽取等基本概念。我这里就不搬运了，这是一个逐步熟悉和了解的过程。\n",
    "<br>\n",
    "\n",
    "# 1.1 多项式曲线拟合\n",
    "- **输入**\n",
    "训练集 【本例只展示10个数据点】\n",
    "$$x\\equiv (x_1,...,x_N)^T$$\n",
    "$$t\\equiv (t_1,...,t_N)^T$$\n",
    "\n",
    "- **输出**\n",
    "拟合曲线\n",
    "\n",
    "## 1.1.1 代码如下\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "X = np.linspace(0, 1, 10)\n",
    "y = np.sin(2*np.pi*X) + np.random.normal(0.1, 0.1, 10)  # 加入噪声\n",
    "X_true = np.linspace(0, 1, 256, endpoint=True)\n",
    "y_true = np.sin(2*np.pi*X_true)\n",
    "\n",
    "plt.scatter(X, y, c=\"b\", alpha=0.6)\n",
    "plt.plot(X_true, y_true, c=\"g\")\n",
    "plt.show()\n",
    "```\n",
    "<center>\n",
    "![](https://raw.githubusercontent.com/markup1/Photos/master/17-8/1.1.png)\n",
    "</center>\n",
    " <center>图1.1</center>\n",
    "如上图所示，可以看到绿色的是潜在的待发现的函数$\\sin(2\\pi x)$，也就是我们最终想预测到对拟合曲线，但是现在根据输入【10个点的数据集】来进行拟合的。\n",
    "<br>\n",
    "\n",
    "\n",
    "## 1.1.2 一些推导\n",
    "我们用一个公式来拟合这些点。假设这个公式是一个关于$x$的多项式。\n",
    "$$y(x,\\omega)=\\omega_0+\\omega_1x+\\omega_2x^2+...+\\omega_Mx^M=\\sum_{j=0}^{M}{\\omega_jx^j}$$\n",
    "\n",
    "- 上面公式中$M$表示多项式的阶数\n",
    "- 当$M=1$时，为简单的线性回归方程\n",
    "\n",
    "**当$M=0$或$M=1$时，拟合曲线如下图红线所示**\n",
    "<center>\n",
    "![](https://raw.githubusercontent.com/markup1/Photos/master/17-8/1.2.png)\n",
    "</center>\n",
    "<center>图1.2</center>\n",
    "我们肉眼可以看到，拟合效果是非常差的。我们怎么量化这种训练时的误差呢？故引出下面常见的一种度量方法。\n",
    "**每个数据点的预测值$y(x_n,\\omega)$和真实值$t_n$之间的平方和**\n",
    "$$E(\\omega)=\\frac{1}{2}\\sum_{n=1}^{N}{[y(x_n,\\omega)-t_n]^2}$$\n",
    "- 这个$E(\\omega)$很明显越小越好\n",
    "\n",
    "**接下来我们看一看当$M$较大时候的曲线**\n",
    "<center>\n",
    "![](https://raw.githubusercontent.com/markup1/Photos/master/17-8/1.3.png)\n",
    "</center>\n",
    "\n",
    "<center>图1.3</center>\n",
    "可以看到当$M=3$时，拟合曲线较好。当$M=9$时所有的点都在拟合的曲线上了，但是这样回造成**过拟合**\n",
    ">在统计学中，过拟合（英语：overfitting，或称过度拟合）现象是指在拟合一个统计模型时，使用过多参数。对比于可获取的数据总量来说，一个荒谬的模型只要足够复杂，是可以完美地适应数据。——[维基百科](https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9)\n",
    "\n",
    "**解决过拟合的方法较多，如调节模型参数数量，让模型变得简单；加入正则项惩罚模型的复杂度，增加训练集的个数**\n",
    "\n",
    "<center>\n",
    "![](https://raw.githubusercontent.com/markup1/Photos/master/17-8/1.4.png)\n",
    "</center>\n",
    "<center>图1.4</center>\n",
    "**正则化**\n",
    "\n",
    "我们给误差函数(1.2)增加一个惩罚项。如下所示：\n",
    "$${E}(\\omega)=\\frac{1}{2}\\sum_{n=1}^{N}{[y(x_n,\\omega)-t_n]^2}+\\frac{\\lambda }{2} \\left \\| \\omega \\right \\|^2$$\n",
    "\n",
    "其中$$\\left \\| \\omega \\right \\|^2=\\omega^T\\omega=\\omega_{0}^{2}+\\omega_{1}^{2}+ ...+\\omega_{M}^{2}$$\n",
    "\n",
    "- **统计学**  : 收缩法(shrinkage)【xgboost也会用到此方法】\n",
    "- **神经网络**: 权值衰减(weight decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
