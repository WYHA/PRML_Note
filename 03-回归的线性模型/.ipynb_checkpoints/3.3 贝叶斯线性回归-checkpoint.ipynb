{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.0 前言\n",
    "---\n",
    "\n",
    "之前我们讲到了利用**最大似然估计Maximum likelihood estimation (ML)**和**最大后验估计Maximum a posteriori estimation (MAP)**进行预测。这一节，我么从贝叶斯的观点来看待回归问题。\n",
    "\n",
    "- 最大似然估计的缺点是：当数据比较少的时候容易过拟合\n",
    "- MAP是在ML的基础上加了先验。也就是加入了正则化，但是我们不知道是使用L1正则还是L2正则\n",
    "\n",
    "下面介绍贝叶斯线性回归\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## 3.3.1 参数分布\n",
    "---\n",
    "对回归问题，比如岭回归问题，我们有：\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{2} \\Vert \\hat{y} - y \\Vert^2_2 + \\frac{\\lambda}{2} \\Vert W \\Vert^2_2\n",
    "$$\n",
    "\n",
    "从贝叶斯的观点看：贝叶斯方法就是先假设参数的一个已知先验，然后求解后验概率的方法。因为似然函数是$w$的二次函数的指数形式。所以整个参数$w$服从高斯分布。\n",
    "\n",
    "$$\n",
    "p(w) = N(w|w_{0},S_{0}) \\tag{3.48}\n",
    "$$\n",
    "\n",
    "接下来计算后验分布,它正⽐于似然函数与先验分布的乘积:\n",
    "\n",
    "$$\n",
    "\\text{posterior} \\propto \\text{likelihood} \\times \\text{prior}\n",
    "$$\n",
    "\n",
    "由第二章高斯分布似然原理可知后验概率分布的形式为:\n",
    "\n",
    "$$\n",
    "p(w|t) = N(w|m_{N},S_{N}) \\tag{3.49}\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "$$\n",
    "m_{N}=S_{N}(S_{0}^{-1}m_{0}+\\beta\\Phi^{T}t) \\\\\n",
    "S_{N}^{-1}=S_{0}^{-1}+\\beta\\Phi^{T}\\Phi\n",
    "$$\n",
    "\n",
    "我们知道，后验概率分布可以由对数似然函数和先验的乘积得到，而回归问题的对数似然函数是一个高斯形式，因而把后验看做$w$的函数，两边取对数即可得：\n",
    "\n",
    "$$\n",
    "\\ln\\ p(w|t)=-\\frac{\\beta}{2}\\sum_{n=1}^{N}\\left \\{ t_{n} - w^{T}\\phi(x_{n}) \\right \\}^{2}-\\frac{\\alpha}{2}w^{T}w+常数 \\tag{3.55}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直线拟合的贝叶斯学习过程\n",
    "\n",
    "考虑一个线性模型为\n",
    "$$\n",
    "y(x,w)=w_{1}x_{1}+w_{2}x_{2}\n",
    "$$\n",
    "\n",
    "![](https://raw.githubusercontent.com/data2world/PRML_Note/master/IMG/CH03/else3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如上图所示**\n",
    "- 左边的图片是$\\mathrm{\\bf{w}}$的似然函数$p(t|x,\\mathrm{\\bf{w}})$\n",
    "- 中间的图片是先验/后验(第一行的先验和第二行的似然（左边）相乘得到第二行的后验)\n",
    "- 右边的是在后验中抽取6个$\\mathrm{\\bf{w}}$来拟合$y(x, \\mathrm{\\bf{w}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3.2 预测分布\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测分布就是给出$x$的值，让你求$y$。我们当然可以从参数$\\mathrm{\\bf{w}}$中选一组进行预测。但是更好的方法是归纳一下所有的$\\mathrm{\\bf{w}}$\n",
    "\n",
    "$$\n",
    "p(t) = \\int p(t,\\mathrm{\\bf{w}}){\\rm d}\\mathrm{\\bf{w}} = \\int p(t|\\mathrm{\\bf{w}})p(\\mathrm{\\bf{w}}){\\rm d}\\mathrm{\\bf{w}}\n",
    "$$\n",
    "\n",
    "- $\\mathrm{\\bf{t}}$是我们的目标向量，那么就有\n",
    "\n",
    "$$\n",
    "p(t|\\mathrm{\\bf{t}}) = \\int p(t|\\mathrm{\\bf{w}})p(\\mathrm{\\bf{w|t}}){\\rm d}\\mathrm{\\bf{w}}\n",
    "$$\n",
    "\n",
    "对于参数$\\alpha, \\beta, x, t$，我们有：\n",
    "$$\n",
    "p(t|\\mathrm{\\bf{t}},\\alpha,\\beta)=\\int p(t|\\mathrm{\\bf{w}},\\beta)p(\\mathrm{\\bf{w}}|\\mathrm{\\bf{t}},\\alpha,\\beta){\\rm d}\\mathrm{\\bf{w}} \\tag{3.57}\n",
    "$$\n",
    "\n",
    "\n",
    "对**式（3.57）**,其中第一项$p(t|\\mathrm{\\bf{w}},\\beta)$由3.1节中的**式（3.8）**：\n",
    "$$\n",
    "p(t|\\mathrm{\\bf{x,w,\\beta}})=N(t|y(\\mathrm{\\bf{x,w}}),\\beta^{-1})\n",
    "$$\n",
    "\n",
    "第二项$w$的后验$p(\\mathrm{\\bf{w}}|\\mathrm{\\bf{t}},\\alpha,\\beta)$：\n",
    "$$\n",
    "p(\\mathrm{\\bf{w}}|\\mathrm{\\bf{t}})=N(\\mathrm{\\bf{w}}|\\mathrm{\\bf{m_N}},S_N)\n",
    "$$\n",
    "其中：\n",
    "- $\\mathrm{\\bf{m_N}}=\\beta S_N \\Phi^T \\mathrm{\\bf{t}}$\n",
    "- $S_N^{-I}=\\alpha I+\\beta \\Phi^T \\Phi$\n",
    "\n",
    "那么预测分布的形式就是两个高斯分布的卷积：\n",
    "$$\n",
    "p(t|x,\\mathrm{\\bf{t}},\\alpha,\\beta)=N(t|\\mathrm{\\bf{m}}_{N}^{T}\\phi(x),\\sigma_{N}^{2}(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测分布的方差：\n",
    "$$\n",
    "\\sigma _{N}^{2}(x)=\\frac{1}{\\beta }+\\Phi(x)^{T}S_{N}\\Phi(x)\n",
    "$$\n",
    "\n",
    "方差的第一项是表示数据的噪声。第二项表示与参数$w$关联的不确定性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测分布的例子：\n",
    "\n",
    "- **数据：数据从$\\sin(2\\pi x)$中draw的**\n",
    "- **模型：使用9个高斯做基函数**\n",
    "$$\n",
    "y(x,w)=\\sum^8_{j=0}w_j\\phi_j(x)=W^T\\phi(x) \\\\\n",
    "\\phi_j(x) = \\mathrm{exp}\\left[\\frac{(x-\\mu_j)^2} {2\\sigma^2}\\right]\n",
    "$$\n",
    "\n",
    "- **预测分布：**\n",
    "$$\n",
    "p(t|x,\\mathrm{\\bf{t}},\\alpha,\\beta)=N(t|\\mathrm{\\bf{m}}_{N}^{T}\\phi(x),\\sigma_{N}^{2}(x)) \\\\\n",
    "\\sigma _{N}^{2}(x)=\\frac{1}{\\beta }+\\Phi(x)^{T}S_{N}\\Phi(x)\n",
    "$$\n",
    "![](https://raw.githubusercontent.com/data2world/PRML_Note/master/IMG/CH03/3.8.png)\n",
    "\n",
    "\n",
    "- **红色的线表示高斯的预测分布，粉色的区域表示预测分布的标准差，可以看到，当N越来越大时，预测分布的标准差区域越小，即方法的影响只和噪声有关**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3.3 等价核\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面**式(3.49)**说到后验的均值$w$为：\n",
    "$$\n",
    "m_{N}=S_{N}(S_{0}^{-1}m_{0}+\\beta\\Phi^{T}t) \\\\\n",
    "S_{N}^{-1}=S_{0}^{-1}+\\beta\\Phi^{T}\\Phi\n",
    "$$\n",
    "上式中的$S_0$是先验$p(w)$的协方差矩阵, $\\beta$是噪声参数，$\\Phi$是设计矩阵。\n",
    "\n",
    "\n",
    "对于高斯分布的先验而言，得到的后验恰好也是高斯分布，最大后验的权向量结果必然是$w_MAP=m_N$，所以，现在预测均值可以写成：\n",
    "$$\n",
    "y(x,m_{N})=m_{N}^{T}\\phi(x)=\\beta\\phi(x)^{T}S_{N}\\Phi^{T}t=\\sum_{n=1}^{N}\\beta\\phi(x)^{T}S_{N}\\phi(x_{n})t_{n}=\\sum_{n=1}^{N}k(\\mathrm{x},\\mathrm{x_n})t_n\n",
    "$$\n",
    "\n",
    "其中：\n",
    "$$\n",
    "k(\\mathrm{x},\\mathrm{x}^{'})=\\beta\\phi(\\mathrm{x})^{T}S_{N}\\phi(\\mathrm{x}^{'})\n",
    "$$\n",
    "上式就是等价核。\n",
    "\n",
    "线性模型可以表达成参数模型和非参数模型。非参数模型里面最重要的概念是两个样本之间的相似度，也就是核。比如我们想对$x_{new}$进行预测得到$y_{new}$，并且在遇到$x_{new}$之前我们已经见到了n个样本$\\{(x_i, y_i) : i = 1,...,n\\}$，那么$x_{new}$的预测值和这$n$个样本都有关系，关系的大小度量就是核$k(x_{new},x_i)$。所以我们可以把每个核看做一个权值，预测结果就是\n",
    "$$\n",
    "y_{new}=\\sum_{i=1}^n{k(x_{new}, x_i)y_i}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Refrence\n",
    "---\n",
    "\n",
    "- [1] https://wiseodd.github.io/techblog/2017/01/05/bayesian-regression/\n",
    "- [2] https://www.zhihu.com/question/39261977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "880px",
    "left": "0px",
    "right": "1708px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
